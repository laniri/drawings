#!/usr/bin/env python3
"""
Post-commit Git hook for automatic documentation regeneration.

This hook automatically regenerates documentation after commits that affect:
- API endpoints
- Service implementations
- Database models
- Frontend components
- Configuration files
"""

import os
import sys
import subprocess
from pathlib import Path
from typing import List, Set, Dict, Any
import json
from datetime import datetime

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from scripts.generate_docs import DocumentationEngine, DocumentationType
except ImportError as e:
    print(f"âŒ Failed to import documentation modules: {e}")
    print("Make sure you're running from the project root with proper dependencies installed.")
    sys.exit(1)


class PostCommitDocGenerator:
    """Post-commit documentation generator."""
    
    def __init__(self):
        self.project_root = project_root
        self.docs_engine = DocumentationEngine(self.project_root)
        self.log_file = self.project_root / ".kiro" / "cache" / "post_commit_log.json"
        self.log_file.parent.mkdir(parents=True, exist_ok=True)
        
    def get_commit_info(self) -> Dict[str, Any]:
        """Get information about the latest commit."""
        try:
            # Get commit hash
            hash_result = subprocess.run(
                ["git", "rev-parse", "HEAD"],
                capture_output=True,
                text=True,
                check=True
            )
            commit_hash = hash_result.stdout.strip()
            
            # Get commit message
            msg_result = subprocess.run(
                ["git", "log", "-1", "--pretty=%B"],
                capture_output=True,
                text=True,
                check=True
            )
            commit_message = msg_result.stdout.strip()
            
            # Get changed files
            files_result = subprocess.run(
                ["git", "diff-tree", "--no-commit-id", "--name-only", "-r", commit_hash],
                capture_output=True,
                text=True,
                check=True
            )
            changed_files = [f for f in files_result.stdout.strip().split('\n') if f]
            
            return {
                'hash': commit_hash,
                'message': commit_message,
                'files': changed_files,
                'timestamp': datetime.now().isoformat()
            }
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ Failed to get commit info: {e}")
            return {}
    
    def should_regenerate_docs(self, commit_info: Dict[str, Any]) -> bool:
        """Determine if documentation should be regenerated based on commit."""
        if not commit_info or not commit_info.get('files'):
            return False
        
        # Skip if commit message indicates docs-only change
        commit_message = commit_info.get('message', '').lower()
        if any(keyword in commit_message for keyword in ['docs only', '[docs]', 'documentation only']):
            print("ğŸ“‹ Skipping doc generation for docs-only commit")
            return False
        
        # Check if any changed files affect documentation
        changed_files = commit_info['files']
        doc_affecting_patterns = [
            'app/',           # Backend code changes
            'frontend/',      # Frontend code changes
            'alembic/',       # Database migrations
            'requirements',   # Dependency changes
            'package.json',   # Frontend dependencies
            'docker-compose', # Deployment changes
            'Dockerfile',     # Container changes
        ]
        
        for file_path in changed_files:
            for pattern in doc_affecting_patterns:
                if pattern in file_path:
                    return True
        
        return False
    
    def categorize_changes(self, changed_files: List[str]) -> Set[DocumentationType]:
        """Categorize changed files to determine which docs to regenerate."""
        affected_types = set()
        
        for file_path in changed_files:
            # API documentation
            if '/api/' in file_path or '/endpoints/' in file_path:
                affected_types.add(DocumentationType.API)
            
            # Service and algorithm documentation
            if '/services/' in file_path:
                affected_types.add(DocumentationType.SERVICES)
                affected_types.add(DocumentationType.ALGORITHMS)
            
            # Database documentation
            if '/models/' in file_path or '/alembic/' in file_path:
                affected_types.add(DocumentationType.DATABASE)
            
            # Frontend documentation
            if '/frontend/' in file_path or file_path.endswith(('.tsx', '.ts', '.jsx', '.js')):
                affected_types.add(DocumentationType.FRONTEND)
            
            # Deployment documentation
            if any(pattern in file_path for pattern in ['docker', 'deploy', 'requirements', 'package.json']):
                affected_types.add(DocumentationType.DEPLOYMENT)
            
            # Workflow documentation (affected by service or API changes)
            if '/services/' in file_path or '/api/' in file_path or '/frontend/' in file_path:
                affected_types.add(DocumentationType.WORKFLOWS)
        
        # Architecture documentation is affected by any significant changes
        if affected_types:
            affected_types.add(DocumentationType.ARCHITECTURE)
        
        return affected_types
    
    def regenerate_documentation(self, commit_info: Dict[str, Any]) -> bool:
        """Regenerate documentation based on commit changes."""
        print(f"ğŸš€ Regenerating documentation for commit {commit_info['hash'][:8]}...")
        
        try:
            # Determine affected documentation types
            affected_types = self.categorize_changes(commit_info['files'])
            
            if not affected_types:
                print("ğŸ“‹ No documentation types affected by changes")
                return True
            
            print(f"ğŸ“ Regenerating: {[t.value for t in affected_types]}")
            
            # Generate documentation for affected types
            success = True
            generated_files = []
            
            for doc_type in affected_types:
                print(f"  Generating {doc_type.value} documentation...")
                
                try:
                    result = self.docs_engine.generate_category(doc_type)
                    
                    if result.success:
                        generated_files.extend(result.generated_files)
                        if result.warnings:
                            print(f"    âš ï¸  {len(result.warnings)} warnings")
                    else:
                        print(f"    âŒ Failed: {'; '.join(result.errors)}")
                        success = False
                        
                except Exception as e:
                    print(f"    âŒ Error generating {doc_type.value}: {e}")
                    success = False
            
            # Update documentation index
            if success and generated_files:
                print("  Updating documentation index...")
                self.docs_engine.update_documentation_index()
                generated_files.append(self.project_root / "docs" / "README.md")
            
            # Log the generation result
            self._log_generation_result(commit_info, success, generated_files, affected_types)
            
            if success:
                print(f"âœ… Documentation regeneration complete! ({len(generated_files)} files updated)")
                
                # Optionally stage and commit the generated documentation
                if self._should_auto_commit_docs():
                    self._commit_generated_docs(generated_files, commit_info)
            else:
                print("âŒ Documentation regeneration had errors")
            
            return success
            
        except Exception as e:
            print(f"âŒ Documentation regeneration failed: {e}")
            self._log_generation_result(commit_info, False, [], set(), str(e))
            return False
    
    def _should_auto_commit_docs(self) -> bool:
        """Check if generated documentation should be auto-committed."""
        # Check for environment variable or config file setting
        auto_commit = os.environ.get('AUTO_COMMIT_DOCS', 'false').lower()
        return auto_commit in ('true', '1', 'yes')
    
    def _commit_generated_docs(self, generated_files: List[Path], commit_info: Dict[str, Any]):
        """Automatically commit generated documentation."""
        if not generated_files:
            return
        
        try:
            print("ğŸ“ Auto-committing generated documentation...")
            
            # Stage generated files
            for file_path in generated_files:
                if file_path.exists():
                    subprocess.run(
                        ["git", "add", str(file_path)],
                        check=True,
                        capture_output=True
                    )
            
            # Check if there are any changes to commit
            status_result = subprocess.run(
                ["git", "status", "--porcelain"],
                capture_output=True,
                text=True,
                check=True
            )
            
            if status_result.stdout.strip():
                # Commit the changes
                commit_message = f"docs: auto-update documentation for {commit_info['hash'][:8]}"
                subprocess.run(
                    ["git", "commit", "-m", commit_message],
                    check=True,
                    capture_output=True
                )
                print("âœ… Generated documentation committed automatically")
            else:
                print("ğŸ“‹ No documentation changes to commit")
                
        except subprocess.CalledProcessError as e:
            print(f"âš ï¸  Failed to auto-commit documentation: {e}")
    
    def _log_generation_result(self, commit_info: Dict[str, Any], success: bool, 
                             generated_files: List[Path], affected_types: Set[DocumentationType],
                             error: str = None):
        """Log the documentation generation result."""
        try:
            # Load existing log
            log_data = []
            if self.log_file.exists():
                try:
                    with open(self.log_file, 'r') as f:
                        log_data = json.load(f)
                except (json.JSONDecodeError, IOError):
                    log_data = []
            
            # Add new entry
            log_entry = {
                'timestamp': datetime.now().isoformat(),
                'commit_hash': commit_info.get('hash', 'unknown'),
                'commit_message': commit_info.get('message', ''),
                'success': success,
                'affected_types': [t.value for t in affected_types],
                'generated_files': [str(f.relative_to(self.project_root)) for f in generated_files],
                'error': error
            }
            
            log_data.append(log_entry)
            
            # Keep only last 50 entries
            log_data = log_data[-50:]
            
            # Save log
            with open(self.log_file, 'w') as f:
                json.dump(log_data, f, indent=2)
                
        except Exception as e:
            print(f"âš ï¸  Failed to log generation result: {e}")
    
    def run_post_commit(self) -> bool:
        """Run post-commit documentation generation."""
        print("ğŸ”„ Running post-commit documentation generation...")
        
        # Get commit information
        commit_info = self.get_commit_info()
        
        if not commit_info:
            print("âŒ Failed to get commit information")
            return False
        
        print(f"ğŸ“Š Commit: {commit_info['hash'][:8]} - {commit_info['message'][:50]}...")
        print(f"ğŸ“Š Changed files: {len(commit_info['files'])}")
        
        # Check if documentation should be regenerated
        if not self.should_regenerate_docs(commit_info):
            print("ğŸ“‹ No documentation regeneration needed")
            return True
        
        # Regenerate documentation
        return self.regenerate_documentation(commit_info)


def main():
    """Main entry point for post-commit hook."""
    generator = PostCommitDocGenerator()
    
    try:
        success = generator.run_post_commit()
        
        # Don't fail the commit if documentation generation fails
        # Just log the issue and continue
        if not success:
            print("âš ï¸  Documentation generation had issues, but commit will proceed")
        
        sys.exit(0)  # Always exit successfully to not block commits
        
    except KeyboardInterrupt:
        print("\nâš ï¸  Documentation generation interrupted by user")
        sys.exit(0)
    except Exception as e:
        print(f"âŒ Post-commit hook failed with error: {e}")
        sys.exit(0)  # Don't fail the commit


if __name__ == "__main__":
    main()